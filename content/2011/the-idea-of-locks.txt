---
title: The idea of locks
author: Michaelhughes
date: 18.06.2011
filter: [rst, ]
tags: [C, Linux, pthreads]
---

First some background, even someone with a single day's worth of programming experience has likely used a '++' operator or something similar to it. For instance, suppose I have a variable called size that counts the number of items in a list and every time I add something to the list size it is incremented by 1. The snippet might be like the following (using a vaguely C like 'faux' object structure pattern):

::


   list_add(list_t *list, void *item) {

     list->size++;

     if(list->tail)  list->tail->next = item;

     list->tail = list->next;

     ...more code

   }


Ignoring the `race conditions <http://en.wikipedia.org/wiki/Race_condition#Computing>`_ present in the code to *actually* add the item to the list, the statement: ``list->size++;`` creates a race by itself. The race can be spotting without delving into how ``list->size++;`` is turned into assembly and then machine code. In short, the ++ operator actually does 3 things. It reads a value, in this case size, increases the value of size by one, and then writes new value of size back to wherever it was read from. The key point being that '++'  is not atomic (aside: there is no guarantee its sub-operations are atomic either), that is while '++' is operating it's possible for another piece of code to *simultaneously read the value of size or even write to size.* The most common situation for a simple data race like this to occur are in multithreaded applications, where two threads executing the same code snippet access the same data structure, such as the list\_add operation above.

Obviously the above example is simple and real applications will likely have more complex data structures and there are multiple ways of addressing potential races. For now though lets suppose we just want to make list->size++; safe.

The main idea is to impose an order on the threads when operating on a shared data structure, such that only one thread at a time manipulates the data. We don't care about *what* the order is, just that there is some order. This can be done with the pthreads library on POSIX systems. The general idea is to lock a section of code such that only one instance of it can execute at time. Pthreads provided two primitives for this purpose, a spinlock and a mutex. We'll use the mutex (short for mutual exclusion), but at this level they function similarly.

Now assume we've already defined the list\_t structure to include a mutex lock, i.e:

::


   typedef struct {

     ...

     pthread_mutex_t lock;

     ...

   } list_t;


And further we assume that the lock is initialized when the list\_t is created using pthread\_mutex\_init(&lock).

Then we can rewrite the above code to make ``list->size++;`` thread safe:

::


   list_add(list_t *list, void *item) {

     pthread_mutex_lock(&list->lock);

     list->size++;

     pthread_mutex_unlock(&list->lock);

     if(list->tail)  list->tail->next = item;

     list->tail = list->next;

     ...more code

   }


The first thread that calls ``pthread_mutex_lock(&list->lock)`` proceeds to execute the increment statement. Other threads that call ``pthread_mutex_lock(&list->lock)`` subsequently block and cannot proceed to executing the increment until the lock is unlocked by the first thread calling ``pthread_mutex_unlock(&list->lock)``. After the lock is unlocked one of blocked threads will be able to get the lock and proceed, it is important to note that *who* gets the lock is not deterministic; some thread will get the lock, but we don't know which. Now the statement ``list->size++;`` is thread safe, and not subject to a data race. Obviously this is a simple example of a complex subject, but hopefully the beginnings of the main idea are clear.

For futher reading:

-  `A pthreads tutorial <http://www.yolinux.com/TUTORIALS/LinuxTutorialPosixThreads.html>`_
-  `A good MSDN article <http://msdn.microsoft.com/en-us/magazine/cc163744.aspx>`_ that goes into way more depth than I did here
